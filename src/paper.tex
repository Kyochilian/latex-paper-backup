\documentclass[conference]{IEEEtran}   % 单栏会议模板；去 conference 选项即双栏

\usepackage[UTF8, scheme = plain]{ctex} % 中文支持

\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{microtype}

% --------- 数学与定理 ---------
\usepackage{amsmath, amssymb, amsthm}
% --------- 图、表、算法环境 ---------
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{array}
\usepackage{subcaption}

\usepackage{algorithm}
\usepackage{algpseudocode}   % 伪代码
% --------- 颜色、引用、超链接 ---------
\usepackage{cite}
\usepackage{xcolor}

\usepackage[hidelinks]{hyperref}
% ---------------- 定理环境 ----------------P
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{remark}{Remark}

% ---------------- 自定义命令 ----------------
\newcommand{\ie}{\textit{i.e.}}
\newcommand{\eg}{\textit{e.g.}}
\newcommand{\etal}{\textit{et al.}}

% ---------------- 正文开始 ----------------
\begin{document}

\title{基于Stage扫描机制的Vision RWKV让医学影像分割轻量而高效}

\author{
\IEEEauthorblockN{
sora\IEEEauthorrefmark{1},
Zhendong~Li\IEEEauthorrefmark{1}}
\IEEEauthorblockA{\IEEEauthorrefmark{1}Ningxia University \\
Email: kyochilian@gmail.com, lizhendong@nxu.edu.cn}
}

\maketitle

\begin{abstract}
基于Transformer的分割框架是当前医学影像分割的主流方法，能够构建全局关系。
然而，在需要高精度与高分辨率的医学图像分割中，Transformer计算复杂度高，应用有限。
最近的RWKV模型降低了空间聚合复杂度并具备全局处理能力，但其在视觉领域存在长程建模羸弱的问题，贪吃蛇效应突出，同时循坏嵌套机制在分割领域中的解码性能不足。
为了解决这些问题，我们提出了一种基于Vision RWKV的分割框架RWKV-SSS，该框架在具有较低复杂度的同时具备了全局建模能力。
为了增强RWKV的长程空间连续性，我们设计了一种Stage扫描机制，该机制将图像分为全局block与局部block，根据不同Stage的编码器，相应调整扫描比例，
将全局与局部特征融合，大大提升了模型的精度。
同时，我们在解码器中构建了上采样模块---，该模块改良了RWKV的循环嵌套机制，提升了重建多尺度特征的能力。
我们还采用多种方法进一步降低SSS的计算复杂度，实现模型的轻量化。（LRFormer 低分辨率自注意力，池化QKV等等）
实验表明，我们的方法在多个数据集取得优异性能，同时计算复杂度与计算速度显著增强，使其在高精度分割的同时具备轻量化特性。
代码开源至：\url{https://github.com/shepherdxu/SCI-winning}。
\end{abstract}

\begin{IEEEkeywords}
computer vision, semantic segmentation, RWKV, Transformer, lightweight
\end{IEEEkeywords}

\section{Introduction}
\IEEEPARstart{S}{emantic} Segmentation 是计算机视觉中的一项重要任务，医学影像分割是关键应用之一。它将复杂的医学图像分割成不同的区域，
使器官、病灶及注意区域清晰可见，对于医学辅助诊断与治疗具有重要意义。
相较于人工，使用计算机视觉技术进行辅助诊断不仅提高了诊断效率，还提升了诊断精度，因此许多方法被提出用于医学影像分割任务。
多年来，传统的ML（机器学习）方法在研究中被广泛应用，如基于图割（Graph Cut）的方法~\cite{Graph Cut}、随机森林（Random Forest）~\cite{Random Forest}、
支持向量机(Support Vector Machine, SVM)~\cite{SVM}以及条件随机场(Conditional Random Field, CRF)~\cite{Conditional Random Field}等。
这些方法依赖人工设计的特征提取器,在处理复杂医学图像时存在局限性，
由于图像存在模糊、噪声、对比度低等问题，传统方法的准确性和鲁棒性受到限制。

近年来，随着FCN(Full Convolution Network)~\cite{FCN}、CNN(Convolution Natural Network)~\cite{CNN}的提出，深度学习方法逐渐代替了传统机器学习方法，
语义分割方法的网络深度、特征提取均有了较大提高。
随着Unet~\cite{Unet}的提出，基于深度学习的分割方法占据了主导地位，通过创新性的U型架构，使其成为了语义分割的主流框架，涌现了Unet++~\cite{unet++}、
Attention-Unet~\cite{attetion-unet}等方法。
2017年，Google提出的Transformer~\cite{Transformer}在自然语言处理（NLP）领域have maked深远影响，which为视觉领域带来了ViT(Vision Transformer)~\cite{ViT} in 2020，
使得计算机视觉领域拥有了全局注意力(Global Attention)与自注意力机制(Self-Attention)~\cite{Transformer}，makes better for全局语义信息提取，改善了CNN的不足~\cite{lack for CNN}。
**等人提出了TransUnet~\cite{TransUnet}，将Unet与CNN和Transformer结合起来，使得医学图像分割方法的精度大大提高。

目前，主流的方法主要遵循TransUnet的思路，在上述深度学习方法中作修改~\cite{分割方法综述}，将CNN作为局部注意力提取~\cite{EViT-Unet}，为了进行更高精度的分辨，
将Transformer作为把握全局特征的模块，采用类似Unet的上下采样与skip connection的结构，达到期望的分割
效果~\cite{Medical Image Segmentation: A Comprehensive Review of Deep Learning Methods}。
然而，医学图像具有低对比度、高分辨率、目标边界模糊等诸多问题~\cite{feature of medical img}，对于自注意力机制来说缺乏友好，往往需要花费大量的参数来提取低对比度医学特征，
牺牲了时间与空间性能~\cite{lack of Transformer on medical image}，
同时自注意力机制具有平方复杂度，高分辨率的医学图像会使计算复杂度大大增加，高参数网络也不适宜部署在医院等边缘设备，这些限制了Transformer在医学图像上的直接应用~\cite{transunet}
~\cite{h2former}。

一些研究人员研究改善这种情况。****等人提出了Linear Transformer~\cite{Linear Transformer}，**等人在20xx年提出了Mamba~\cite{Mamba}模型，不同于Transformer的框架，
他们均通过将自注意力机制的复杂度改为线性，从而缓解计算复杂度问题。然而，事实证明，线性复杂度的Transformer变体总会牺牲分割精度与准确率，而Mamba模型的长序列建模（SSM）
也不适用于视觉问题~\cite{mamba out}。鉴于医学影像中 3D 体数据、MRI与CT等高分辨率数据普遍存在，且存在高精度的像素级分割要求，
实践中还需要考虑医院边缘设备的部署问题，如何平衡精度与效率、参数与性能，成为急需解决的问题。

Recurrent Weighted Key-Value(RWKV)~\cite{rwkv}的出现引起了我们的关注。其在NLP领域的线性复杂度注意力机制，不同于Transformer的结构，使其有价值迁移到视觉任务上。
Vision RWKV(VRWKV)~\cite{visionrwkv}尝试了该问题，并针对图像输入进行了结构改进，展现出优异的计算效率与模型精度，**等人提出了BSBP-RWKV~\cite{BSBP-RWKV}，
首次将RWKV应用于医学图像任务，一些研究如RWKV-Unet~\cite{RWKV-UNet}将VRWKV与Unet迁移到医学图像分割任务上。在高分辨率的医学图像任务下，
RWKV优于其他Transformer变体与Mamba模型，处理医学图像输入时的推理速度更高，且效果更好~\cite{rwkv-sam}。

作为一款线性注意力模型，尽管RWKV拥有良好的计算效率与精度，但迁移到图像任务上，还是有不可避免的问题。RWKV本质是沿序列建模的状态空间式结构,
针对离散数据(如自然语言处理)的处理过程是固定的，自注意力的处理方式也是一维的。面对连续且二维的图像，基于RWKV的图像处理方法是将图像分块，
并延展为一维，导致了空间连续性上的破坏~\cite{zigrir}。

在注意力提取过程中，RWKV使用一维的方式在二维图像上进行特征提取，我们称其为贪吃蛇效应~\ref{fig:贪吃蛇效应}。
RWKV的扫描方式是固定的，在图像任务中，注意力的权重往往动态且多变，固定的扫描方式往往会将注意力分片~\cite{visionrwkv}。(如图~\ref{fig:图RWKV的空间连续性破坏})。
若提取到更深层次，图像的特征更容易模糊，RWKV容易将模糊的特征边缘分离，进行分片扫描，导致容易导致器官边缘、细小病灶（如微小息肉、早期病变区）分割不精细，
而这是医学图像分割的要求之一(如图~\ref{fig:RWKV分片将深层次的边缘分割开来})。
同时，医学方向涉及三维数据，在三维医学图像中，边界分割、注意力分片的现象将会更为突出，这为RWKV向医学领域的适配带来了挑战~\cite{med-urwkv}。

为此，很多工作进行了改进。U-RWKV提出了方向自适应 RWKV 模块~\cite{urwkv}，改进了RWKV的扫描方式，使其不仅仅局限于一维层面的注意力叠加。Zig-RiR~\cite{zigrir}提出了
ZigZag的扫描方案，试图解决RWKV扫描的空间连续性问题。然而，其带来了诸多问题：扫描缺乏对图像的动态调整，导致其训练过程不稳定，且不同器官之间的精度存在较大差异
~\ref{fig:ZigRiR与URWKV的训练loss曲线不稳定};同时，贪吃蛇效应仍然存在；两者工作的上采样过于简单，导致恢复特征分辨率时的精度不足，无法满足医学图像像素级分割的要求。

我们的研究致力于解决该问题。受到Vision RWKV~\cite{vrwkv}以及URWKV~\cite{urwkv}的启发，我们提出了一种基于RWKV的U型架构Stage Scan Segmentation，
该架构具备完备的编码器-解码器，在保持了RWKV的长程依赖和线性复杂度的同时，增强了局部细节的表达与分割的精度。具体来说，我们采用了Bi-WKV，一种线性注意力，
作为我们的注意力核心~\cite{vrwkv}，并提出了stage scan，一种基于encoder层次的扫描机制，根据不同层次的编码器，调整扫描方向与比例。
为了解决RWKV的空间连续性问题，SSS将一个维度的模块设置为全局block与局部block，分别提取全局与局部特征。在一开始，输入特征的分辨率
与H、W较大，特征比较分散，噪声较多，需要我们进行更多的分块扫描。随着编码器的Stage增加，输入特征的细节将会更多更集中，
图像的分块数也会随着层数的增加而减少~\ref{fig:不同层次的图像分块}，以此把握全局的注意力。在一个模块的前端，
我们使用全局block，较大的Stage分块，进行初步的特征提取。随后，采用残差机制~\cite{resnet}将提取后的全局权重与原特征加和。
局部block接收加和后的权重，将stage分块进一步增大，进行局部
的特征提取。同时，为了缓解贪吃蛇效应~\ref{fig:贪吃蛇效应}，我们改进了四项token位移~\cite{vrwkv}，根据已确定的扫描机制，动态调整扫描位移的方向。
低参数量~\ref{fig:计算效率与参数量对比}。其次，我们对RWKV的WKV进行适当池化~\cite{lrformer}，实现进一步的轻量化。
最后，我们在上采样阶段实现动态上采样~\cite{dysample}，而不仅仅进行反卷积，进一步保留了分割结果的精度与细节。
通过这种方式，SSS获得优于其他方法的特征捕捉能力~\ref{fig:效果对比图}，增强了对边缘的分割能力和鲁棒性，并发挥了RWKV应有的计算效率与低参数量。

总的来说，我们的贡献有：

1. 使用VRWKV作为分割的核心方法，达到了线性复杂度与注意力精度的平衡；

2. 提出了基于Stage的Scan方法，缓解了贪吃蛇效应，有效提取全局特征与局部特征；

3. 在对多个2d以及3d数据集中，SSS的效果优于目前许多最先进的方法，同时参数量降低了20\%,GPU占用降低了23\%~\ref{fig:资源占用与GPU占用对比图}。


待写：
上采样问题
轻量化问题 所谓的动态？




加入RWKV扫描后的热力图，表示注意力在图像上的衰减



\section{Related Works}
\subsection{医学图像分割}
目前，基于深度学习的医学图像分割网络是主流，且很多的先进方法均基于CNN和Transformer的变体得来。

\textit{1. 纯净的CNN。}最具代表性的为Unet~\cite{Unet}。UNet的优势在于编码器-解码器的结构，并通过跳
跃连接有效减少信息在传输过程中的损失，实现对复杂医学图像中细微结构的精准分割。部分研究者对Unet进行了改进，例如
UNet++、UNet3+、3D UNET和Attention Unet等等。但是，卷积核的有限感受野难以捕捉远程关系和远程关系，限制了模型的分割性能。
同时，在面对大尺寸医学图像或三维图像时，UNet的性能往往不足，导致细节的丢失和全局能力的不足。

\textit{2. 纯净的Transformer。}Transformer的核心机制self-attention使其能够把握全局上下文关系，该机制被大量应用至计算机视觉领域，例如ViT。
Transformer克服了CNN在处理长程依赖关系时的不足，并将每个图像块作为输入序列传递到 Transformer 编码器，以获得图像的全局表示。Liu~\cite{swintransformer}等人设计了
SwinTransformer架构，该架构针对图像分割和目标检测任务设计，并在医学影像分割上取得了不错的成绩。Cao~\cite{swinunet}等人将Unet与Transformer架构融合，
设计了Swin-Unet，提升了医学影像的分割精度和泛化能力。Lin~\cite{dstransunet}等人进行了进一步的改进，采用双尺度编码器子网来提取不同语义尺度的特征，
建立不同尺度之间的依赖关系。采用纯净Transformer的模型对医学图像的精度和鲁棒性较好，但其复杂度较高，精细局部特征提取能力不足，限制了其在医学图像中的应用。


\textit{3. 将CNN与Transformer结合，}利用CNN在捕捉局部特征上的优越性以及Transformer对全局依赖性的处理能力。具有代表性的是TransUNet~\cite{transunet}、
CoTr~\cite{cotr}、UTNet~\cite{utnet}和Transfuse~\cite{transfuse}网络等。这些网络通过各种串行、并行的方式将CNN与Transformer结合到一起，
整合了全局与局部特征，使精度进一步提高。该方法的核心问题是：模型计算复杂度较高。Transformer 模块处理图像任务需要将图像序列化，形成较长的序列。
尽管 ViT 提出了图像块序列，但图像切割后计算量仍然较大；混合模型需要同时维护UNet的卷积层和高复杂度的自注意力机制，虽然增强了细节的
特征提取能力，但模型的参数和推理速度均显著降低，无法部署在医院的大量边缘及低算力设备中，应用有限。


改进~\cite{Medical Image Segmentation: A Comprehensive Review of Deep Learning Methods}。


\subsection{线性注意力}
线性注意力致力于打破二次方级的注意力复杂度瓶颈，使注意力机制更加高效，并催生出了一系列Transformer变体和非Transformer架构。

\textit{1. Transformer变体。}一些针对于Transformer的改进如Linear Transformer~\cite{lineartransformer}，提出了特征映射的概念，用以替代Softmax，
将Attention机制视为Linear RNN的过程。**等人提出了Performer~\cite{performer}，引入了正交随机特征（Orthogonal Random Features, ORF），
使其接近Softmax的效果。二者均通过对softmax函数效果的改进，进而达到线性注意力的目的。以此为基础，Han~\cite{flatten transformer}等人提出了Flatten Transformer，
设计了一种聚焦线性注意力(Focused Linear Attention)，改善了空间特征的完整性，完善了线性注意力在视觉领域的应用。

\textit{2. the new wave。}如经典的mamba~\cite{mamba}模型，其引入了选择性扫描机制（Selective Scan），让模型能够根据输入内容动态压缩记忆。
U-Mamba~\cite{umamba}、Swin-UMamba~\cite{swinumamba}、VM-UNet~\cite{vmunet}等方法探索了Mamba模型在医学图像分割领域的运用，将Mamba模型与SSM的思想
整合进了分割领域当中，并进行了针对性的优化。然而，SSM的核心机制致使其无法有效建模初窗口之外的全局上下文信息，基于SSM的视觉模型与最先进的卷积模型和基于注意力的模型相比，
表现不佳，导致其并不适合视觉任务~\cite{mamba out}，且其运行速度往往以准确率为代价。

\subsection{RWKV}
最近提出的Receptance Weighted Key Value(RWKV) ~\cite{RWKV}是不同于Transformer的线性架构，擅长处理长序列关系与自回归任务，在NLP领域效果优良，
并催生出在视觉领域的一系列运用~\cite{vrwkv}~\cite{RSRWKV}。同时，一些研究人员，也探索了RWKV在医学分割领域的运用~\cite{urwkv}~\cite{rwkv unet}~\cite{zigrir}。

以此为契机，我们继续完善专精于医学分割的RWKV。经过研究，我们发现，RWKV不适宜直接运用至分割任务中，因为原始的因果感受野的机制，在图像任务中表现不好，
同时，各种针对图像分割的改进，没有缓解贪吃蛇效应\ref{fig:贪吃蛇效应}，这导致边界分割模糊，没有达到像素级分割的要求\ref{fig:对比图，分割的边界锯齿明显}，
全局注意力的上下文关系也比较割裂。为了解决该问题，我们提出了Stage scan structure，一种基于Stage的RWKV扫描方法，并将一次处理分为全局block和局部block，
以此，针对特征信息的大小，进行精准的提取，保留了空间连续性。同时，我们改进了Q-shift，四向位移机制，使其动态调整位移方向，有效缓解贪吃蛇效应。额外地，在原有的
Bi-WKV基础上，我们利用低分辨率的WKV实现进一步的轻量化。


\section{Methods}
如图\ref{fig:main-network}所示，我们整体的网络采用了U型架构进行设计，分为下采样、上采样和跳跃连接。其中核心的特征提取在上采样中。整体而言，对于一张待分割的二维医学图像，首先经过stem，
在网络的初始部分，以进行早期的特征提取与图像分块。其次，网络将分块的图像送进encoder中，经过全局SS和局部SS，不断增加网络深度并提取分割特征。在此期间，基于Stage的扫描机制和Dynamic Q-
shift将灵活处理分割精度与边界。在上采样过程中，（参考Gemini的思路），最终输出完整的分割结果。
\subsection{Stem与预处理}
直接使用原始像素pixel-level会导致序列过长，提高计算度和低频噪声的出现概率~\cite{vit}，因此要对输入的图片进行预处理。我们利用卷机的局部归纳偏置，高效地提取初步特征。
图像首先会经过一个3x3的卷积块，经过一个batch normalization(BN)，随后进入
GeLU函数进行激活。这个步骤会进行两次。在两步卷积过程中，图像的空间分辨率会快速缩小，导致在一开始容易丢失边缘细节信息，不利于高精度的语义分割，因此，在初始输入中，我们引入残差连接
~\cite{resnet}将输入图像分枝，送入分枝的3x3卷积中，与一个batch norm，再与原模块加权，在深度不变的情况下增强了特征传递。

定义一张输入二维图像为$X_{in} \in \mathbb{R}^{H \times W \times C_{in}}$。对于医学CT/MRI图像来说，通常$H=W=256, C_{in}=1$。
stem模块的卷积核大小$k=3$,步长$s=2$，经过stem模块后，初始特征图$F_{0} \in \mathbb{R}^{\frac{H}{4} \times \frac{W}{4} \times C_{0}}$，$C_{0}=64$。
可以看出，该模块的总下采样率 $S=4$，Stage $\text{i} \in \{1,...,4\}$。

图像的初步序列化过程被集中到Stage scan structure中。



\subsection{Stage Scan Structure}
初步处理后，我们将特征图分为global branch和local branch，送入Stage Scan Structure(SSS)模块中。SSS模块由多个Stage串联组成，每个Stage包含若干Bi-WKV块。

\textit{1. Multi-Granularity Windows.}

特征图$F_i$进入encoder后，我们对其进行分块，以便于进行特征提取。对于global branch与local branch，我们采用不同窗口粒度的分块方法。
global branch旨在捕捉长距离依赖，window size较大，block数量较少，序列短；local branch旨在捕捉局部细节，window size较小，block数量较多，
序列长\ref{fig:global branch和local branch}。这种不同Granularity的方法使得模型能够在不同尺度上捕捉图像的全局与局部特征，提升了分割的精度。

可以看出，对于stem输入的同一张原始图像$F$，global branch的初始窗口分块可以表示为
\begin{equation}F_{0}\xrightarrow{\;w_g\;}\{g_{1},g_{2},\dots,g_{m_g}\}\end{equation}
其中$m_g=\frac{H_0}{w_g}\cdot\frac{W_0}{w_g}.$代表分块数量，$g_{i} \in \mathbb{R}^{w_g \times w_g \times C_0}$，$w_g$代表global branch的窗口行列。


同样地，local batch的初始窗口分块可以表示为\begin{equation}F_{0}\xrightarrow{\;w_l\;}\{\ell_{1},\ell_{2},\dots,\ell_{m_\ell}\}\end{equation}
其中$m_\ell=\frac{H_0}{w_l}\cdot\frac{W_0}{w_l}.$代表分块数量，$ \ell_{i} \in \mathbb{R}^{w_l \times w_l \times C_0}$，$w_l$代表local branch的窗口行列。
$ l_{i} \in \mathbb{R}^{w_l \times w_l \times C_i}$，$w_l$代表local branch的窗口行列。

local branch的窗口大小小于global branch的窗口大小，即$w_l < w_g$，可以表示为\begin{equation}w_l = \frac{w_g}{\kappa}\end{equation}
其中$\kappa$为$g_{m}$相对于$l_{n}$的缩放系数。

\textit{2. Stage-wise Window Mechanism.}

在SSS模块中，我们设计了Stage-wise Window Mechanism，根据不同Stage的编码器动态地调整global branch与local branch的窗口比例与分块数量。

我们设计SWM的理由是，随着网络层数加深，特征图的$H$与$W$逐渐减小，分辨率降低，语义信息增强，此时需要更多地关注全局上下文信息；
而在浅层语义中，特征图的$H$与$W$较大，分辨率高，噪声较多，需要更多地关注局部细节信息。如图\ref{:stage层数，图像的变化}所示，
现有的RWKV变体如Zig RiR~\cite{zigrir}与URWKV~\cite{urwkv}均采用
固定的扫描方式，没有适应变化的stage，导致模型在不同stage下的表现不佳，无法更好地提取特征。

为此，全局与局部分枝的窗口，需要根据Stage进行调整。在浅层语义中，特征较为分散，噪声与信息较多，需要更多的分块进行扫描提取特征；
在stage深层语义中，特征图尺寸随着stage的增加逐步变小，语义信息变得越来越丰富，此时更需要模型具备理解全局上下文的能力。

以层数stage $i^\star$为变量。设全局窗口边长在所有stage上固定为$w_g=8$。为实现Stage-wise自适应，我们采用分段式比例调度$\kappa(i)$，从而令局部窗口$w_l(i)=w_g/\kappa(i)$随stage变化。
公式如下：
\begin{equation}
\kappa(i) =
\begin{cases}
4, & i\le i^\star,\\
2, & i> i^\star,   
\end{cases}
\qquad
w_l(i)=\frac{w_g}{\kappa(i)}.
\end{equation}
则在第 $i\in \{1,..., 4\}$ 个 stage 上，全局块和局部块分别将特征图$F_s$划分为
\begin{equation}G_i = \frac{H_i}{w},w \in \{w_g, w_l\}\end{equation}
个非重叠的blocks，其中 $H_i = W_i$ ，为输入图像的高宽度,序列长度（总块数）$L_i$即为$G_i$的平方。

总而言之，在第$i$个stage上，Global Branch可以表示为
\begin{equation}
    F_i \xrightarrow{\;w_g\;} \{g_{i,1},\dots,g_{i,L_i^g}\},\qquad 
L_i^g=\frac{H_i}{w_g}\cdot\frac{W_i}{w_g}.
\end{equation}
Local Branch可以表示为
\begin{equation}
    F_i \xrightarrow{\;w_l(i)\;} \{\ell_{i,1},\dots,\ell_{i,L_i^\ell}\},\qquad 
L_i^\ell=\frac{H_i}{w_l(i)}\cdot\frac{W_i}{w_l(i)}.
\end{equation}
明显地，$F$代表输入的特征图，$L$代表序列长度，即分块的总数。

\textit{3. Scan.}

许多线性注意力机制，在计算权重时，依赖 token 的一维序列距离$|t-i|$，这使得它们对序列的方向和顺序非常敏感。
在一张二维图$\mathbf{F}\in\mathbb{R}^{H\times W\times C}$，当其被序列化为token序列时，会产生大量一维序列中相近，但空间二维远离的现象，
称之为伪近邻（false neighbors）。注意力机制学习到大量的伪近邻token，在高权重区域混入不符合二维局部连续性的关系，由此产生只有一维连续性，
但没有二维连续性的贪吃蛇效应~\ref{fig:贪吃蛇效应}。

在不同尺度的特征图上，Bi-WKV~\cite{vrwkv}进行特征提取。在Vision RWKV中，Bi-WKV包含两个WKV模块，分别沿水平与垂直方向进行扫描。
在时间步 $t$ 时，生成的双向加权键值聚合结果$wkv_t$，用公式表示为
\begin{equation}
\begin{aligned}
wkv_t &= \text{Bi-WKV}(K_s, V_s)_t \\
&= \frac{\sum_{i=0, i \neq t}^{T-1} e^{-(|t-i|-1)/T \cdot w + k_i} v_i + e^{u+k_t} v_t}{\sum_{i=0, i \neq t}^{T-1} e^{-(|t-i|-1)/T \cdot w + k_i} + e^{u+k_t}}
\end{aligned}
\label{eq:bi-wkv}
\end{equation}
其中，$K_s$ 和 $V_s$ 分别对应输入序列的键（Key）与值（Value）矩阵；$w$ 是位置相关的衰减因子（Decay factor），用于控制空间或时间距离对权重的影响；
$u$ 代表当前位置的增益系数（Bonus factor）；$T$ 为序列的总长度，用于对距离项进行归一化处理。

如式\ref{eq:bi-wkv}所示，Bi-WKV 的权重，依赖 token 在一维序列中的相对距离，即为$|t-i|$.
对每个 token $\mathbf{x}_t$，其主要有效上下文往往集中在序列邻域 $\mathcal{N}_R(t)=\{i:\ |i-t|\le R\}$，其中的R位有效的窗口半径。
若 $|t-i|$ 小的 token 在二维平面上也相互邻近，则 Bi-WKV 的强权重区域主要聚合真实空间近邻信息；反之，若短序列窗口在二维上跨越较远距离，则会在高权重区域引入大量伪近邻（false neighbors），表现为只有一维连续性而缺乏二维连续性的“贪吃蛇效应”。

不同于之字扫描与蛇形扫描方式，我们使用 \textbf{Hilbert 空间填充曲线（Hilbert space-filling curve）}作为扫描顺序，以更好地对齐 Bi-WKV 的序列衰减结构与图像的二维连续性。

而在 Zig-RiR 中，核心空间混合依赖 Bi-WKV。ZigZag~\cite{zigrir}扫描方式,通过蛇形扫描缓解了空间连续性问题，但最重要的，二维特征序列化后，贪吃蛇效应依然存在。
为此，我们提出了两种解决方案：\textbf{1.Hilbert扫描；2.Dynamic Q-shift。}

传统 raster 扫描会在行尾发生长跳跃，破坏空间连续性；
蛇形扫描虽能缓解 一维序列上的跳跃，但其短序列窗口在二维上仍各向异性明显，存在伪近邻。
我们使用Hilbert扫描方式~\cite{hilbert}替代常规的行优先（raster）或简单蛇形扫描。
Hilbert是一种空间填充曲线，在不同尺度上具有递归结构，使得序列上的连续片段往往对应二维上的一个或少数几个紧凑小方块，减少了伪近邻现象；
在离散网格上，Hilbert是一条连续的遍历路径，相邻序号的点在二维上通常是邻接的，避免了换行导致的跳跃\ref{fig:各种扫描方式对比的图像，包括传统，S字，对角线}。


如图所示，Hilbert扫描的具体公式可以表示为
\begin{equation}
    待写
\end{equation}

其中。。。代表。。。，。。。代表。。。

实验表明，在医学图像分割任务中，Hilbert扫描优于传统的扫描方式以及S字形扫描
~\ref{fig:各种扫描方式对比的可视化实验结果与列表对比图}。 




Zig RiR的两次扫描和为一个BiWKV内进行，计算复杂度为\begin{equation}O=(2TC)\end{equation}

\subsection{Dynamic Q-shift}
虽然改进了Hilbert扫描方式，但二维近邻的空间是割裂的。贪吃蛇仅仅在序列化时改变了爬行方式，而并没有改善更高维的信息交换。

在Vision RWKV中，采用了四向位移机制(Q-shift)~\cite{vrwkv}，通过对token进行四个方向的位移，增强了空间连续性。
这是对网络从一维语义像二维图像的改进，但是，正如上文所说，这种扫描方式，对于序列的方向与顺序较为敏感。同一 张2D 图像，更换一种扫描顺序，相对空间位置会显著变化，从而影响空间连续性。
就像贪吃蛇游戏中，蛇头的移动方向决定了蛇身的走向，而无法关系周围的空间结构与顺序。

在本文网络中，为了缓解贪吃蛇效应，我们对Q-shift进行了改良，使其动态调整位移方向。


缓解贪吃蛇效应。
Q- shift对于不在扫描路径上的token，占比大一些

可以采用对角线扫描
\subsection{Low-Resolution WKV}
主要介绍主要的自注意力机制块，和对应的池化，




\subsection{上采样}

\section{Experiments}
实验结果。与ZigRiR一致。

\begin{table}[h]
\centering
\caption{Top-1 accuracy (\%) on CIFAR-10 under different sparsities.}
\begin{tabular}{lcc}
\toprule
Method & 90\% sparsity & 95\% sparsity \\
\midrule
Baseline & 93.5 & 91.2 \\
Magnitude~\cite{han2015deep} & 92.8 & 89.7 \\
DST (ours) & \textbf{94.1} & \textbf{92.3} \\
\bottomrule
\end{tabular}
\end{table}

\section{Conclusion}
We presented a simple yet effective DST framework that dynamically adjusts sparse connectivity during training.
Future work includes extending DST to transformer architectures.

\section*{Acknowledgment}
This work was supported by the National Natural Science Foundation of China under Grant 62XXXXXX.

\bibliographystyle{IEEEtran}
\begin{thebibliography}{99}



\bibitem{han2015deep}
S.~Han, J.~Pool, J.~Tran, and W.~Dally,
``Learning both weights and connections for efficient neural network,''
\textit{Proc. NIPS}, 2015.

\bibitem{evci2020rigging}
U.~Evci, T.~Gale, J.~Menick, P.~S.~Castro, and E.~Elsen,
``Rigging the lottery: Making all tickets winners,''
\textit{Proc. ICML}, 2020.


\bibitem{FCN}

\bibitem{Graph Cut}

\bibitem{Random Forest}

\bibitem{SVM}

\bibitem{Conditional Random Field}

\bibitem{CNN}

\bibitem{FCN}

\bibitem{Unet}

\bibitem{Transformer}

\bibitem{ViT}


\end{thebibliography}



\end{document}
% ================= end of main.tex =================